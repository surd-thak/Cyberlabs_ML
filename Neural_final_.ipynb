{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural final .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network**"
      ],
      "metadata": {
        "id": "daA-NQffcbit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6WqL4tQQch2m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uHHXzzNdckv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path2 = \"/content/drive/MyDrive/emnist-letters-test.csv\"\n",
        "path1 = \"/content/drive/MyDrive/emnist-letters-train.csv\"\n",
        "\n",
        "Train0 = pd.read_csv(path1, header = None)\n",
        "Train1 = Train0.to_numpy()\n",
        "\n",
        "Test0 = pd.read_csv(path2, header = None)\n",
        "Test1 = Test0.to_numpy()"
      ],
      "metadata": {
        "id": "wfNVKLOrc2qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardisation(A):\n",
        "  A_mean = np.mean(A, axis = 0)\n",
        "  A_std_dev = np.std(A, axis = 0)\n",
        "  A_standardised = (A - A_mean)/ A_std_dev\n",
        "  return A_standardised\n",
        "\n",
        "def feature_scaling(A) : \n",
        "  return np.divide(A, 256)"
      ],
      "metadata": {
        "id": "ljtdVChccnYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train0 = Train1[:,1:]\n",
        "X_train1 = feature_scaling(X_train0)"
      ],
      "metadata": {
        "id": "lcuZ2dtlcvyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test0 = Test1[:,1:]\n",
        "X_test1 = feature_scaling(X_test0)"
      ],
      "metadata": {
        "id": "o43aaKF3cygG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1.shape"
      ],
      "metadata": {
        "id": "2TrFTOqjBAlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P = np.sum(X_train1, axis =1)\n",
        "P.shape"
      ],
      "metadata": {
        "id": "EucdHgCmBHrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Neural_2_layered( iterations, alpha, X, Y) :\n",
        "  #prefferable no. of nodes in hidden layer = sqrt(input layer node * output layer node), here it is approx 142\n",
        "  theta1 = np.random.random([X.shape[1], 142]) - 0.5\n",
        "  theta2 = np.random.random([142,26]) - 0.5\n",
        "  b1 = (np.ones((142, 1)))*0.01\n",
        "  b2 = (np.ones((26, 1)))*0.01\n",
        "  m = X.shape[0]\n",
        "  \n",
        " \n",
        "  for i in range(iterations):\n",
        "    #forward propopgation\n",
        "    superscript1 = (np.dot (X, theta1).T + b1).T #88800,142 -- 142,88800 -- 142,1 broadcasted -- 88800,142\n",
        "    Act1  = 1/(1+(np.exp(-superscript1))) #88800,142\n",
        "\n",
        "    superscript2 = (np.dot (Act1, theta2).T + b2).T #88800,26 -- 26,88800 -- 26,1 broadcasted -- 88800,26\n",
        "    Act2 = 1/(1+(np.exp(-superscript2))) #88800,26\n",
        "    \n",
        "    cost = (1/m)*(np.sum(-Y*(np.log(Act2)) - ((1-Y)*(np.log(1-Act2))))) #88800,26\n",
        "\n",
        "    #backward propogation\n",
        "    dZ2 = (Act2 - Y) #88800,26 \n",
        "    dtheta2 = (1/m) * np.dot(Act1.T, dZ2) #142,26\n",
        "    db2 = (1/m) * np.sum(dZ2, axis = 1) #88800,1\n",
        "    \n",
        "    der_Act1 = Act1*(1-Act1) #88800,142\n",
        "    dZ1 = np.multiply(np.dot(dZ2, theta2.T), der_Act1) #88800,142\n",
        "    dtheta1 = (1/m) * np.dot(X.T, dZ1) #784,142\n",
        "    db1 = (1/m) * np.sum(dZ1, axis = 1) #88800,1\n",
        "\n",
        "    \n",
        "\n",
        "    #parameters update\n",
        "    theta_1 = theta1 - alpha*dtheta1\n",
        "    theta1 = theta_1\n",
        "    b_1 = b1 - alpha*db1\n",
        "    b1 = b_1\n",
        "\n",
        "    theta_2 = theta2 - alpha*dtheta2\n",
        "    theta2 = theta_2\n",
        "    b_2 = b2 - alpha*db2\n",
        "    b2 = b_2\n",
        "\n",
        "    plt.scatter(i, cost)\n",
        "    #plt.scatter(i, theta)  theta is a vector this doesnt make any sense\n",
        "    #if i == 100 :\n",
        "    print (cost)\n",
        "     \n",
        "  return theta1, theta2, b1, b2, Act2"
      ],
      "metadata": {
        "id": "5FtA84Lac1gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Training_label = Train1[:,0]"
      ],
      "metadata": {
        "id": "bd5iM_Zzrl5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y should be only 0 or 1\n",
        "Y_train = np.zeros((Train1.shape[0], 26))\n",
        "for i in range(Train1.shape[0]):\n",
        "    Y_train[i, Training_label[i]-1] = 1\n",
        "pd.DataFrame(Y_train)"
      ],
      "metadata": {
        "id": "pyzxBYUHrpy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta1, theta2, b1, b2, Act2 = Neural_2_layered(150, 1.3, X_train1, Y_train)"
      ],
      "metadata": {
        "id": "row4HDCGrsQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = np.dot (X_test1, theta1) \n",
        "A1  = 1/(1+(np.exp(-s1)))\n",
        "s2 = np.dot (A1, theta2) \n",
        "A2 = 1/(1+(np.exp(-s2)))\n"
      ],
      "metadata": {
        "id": "B88sYG2Pr7Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_max = np.argmax(A2, axis =1)"
      ],
      "metadata": {
        "id": "qqX-xhMtr_DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Test = Test1[:,0]"
      ],
      "metadata": {
        "id": "BQX8fSKQoZpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0 \n",
        "for i in range(Y_Test.shape[0]):\n",
        "    if Y_Test[i] == Y_pred_max[i] + 1:\n",
        "        count+=1"
      ],
      "metadata": {
        "id": "lRJTp2KmsKDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "YBjb1Im-sMA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (count/14799)*100"
      ],
      "metadata": {
        "id": "OhZIemjXsNxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracy"
      ],
      "metadata": {
        "id": "qH4scCAZsPin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def Neural_3_layered( iterations, alpha, X, Y) :\n",
        "  #prefferable no. of nodes in hidden layer = sqrt(input layer node * output layer node), here it is approx 142\n",
        "  theta1 = np.zeros((X.shape[1], 142))\n",
        "  theta2 = np.zeros((142, 61))\n",
        "  theta3 = np.zeros((61, 26))\n",
        "  b1 = np.ones((X.shape[0], 142))\n",
        "  b2 = np.ones((X.shape[0], 61))\n",
        "  b3 = np.ones((X.shape[0], 26))\n",
        "  m = X.shape[0]\n",
        "\n",
        " \n",
        "  for i in range(iterations):\n",
        "    #forward propopgation\n",
        "    superscript1 = np.dot (X, theta1) + b1\n",
        "    Act1  = 1/(1+(np.exp(-superscript1)))\n",
        "\n",
        "    superscript2 = np.dot (Act1, theta2) + b2\n",
        "    Act2 = 1/(1+(np.exp(-superscript2)))\n",
        "\n",
        "    superscript3 = np.dot (Act2, theta3) + b3\n",
        "    Act3 = 1/(1+(np.exp(-superscript3)))\n",
        "    \n",
        "    cost = (1/m)*(np.sum(-Y*(np.log(Act2)) - ((1-Y)*(np.log(1-Act2)))))\n",
        "\n",
        "    #backward propogation\n",
        "    dZ2 = (Act2 - Y)\n",
        "    dtheta2 = (1/m) * np.dot(Act1.T, dZ2)\n",
        "    db2 = (1/m) * np.sum(dZ2, axis = 1, keepdims = True)  #keepdims helps to maintain it as a 2d array\n",
        "    \n",
        "    der_Act1 = Act1*(1-Act1)\n",
        "    dZ1 = np.multiply(np.dot(dZ2, theta2.T), der_Act1)\n",
        "    dtheta1 = (1/m) * np.dot(X.T, dZ1)\n",
        "    db1 = (1/m) * np.sum(dZ1, axis = 1, keepdims = True)\n",
        "\n",
        "    \n",
        "\n",
        "    #parameters update\n",
        "    theta_1 = theta1 - alpha*dtheta1\n",
        "    theta1 = theta_1\n",
        "    b_1 = b1 - alpha*db1\n",
        "    b1 = b_1\n",
        "\n",
        "    theta_2 = theta2 - alpha*dtheta2\n",
        "    theta2 = theta_2\n",
        "    b_2 = b2 - alpha*db2\n",
        "    b2 = b_2\n",
        "\n",
        "    theta_3 = theta3 - alpha*dtheta3\n",
        "    theta3 = theta_3\n",
        "    b_3 = b3 - alpha*db3\n",
        "    b3 = b_3\n",
        "\n",
        "    plt.scatter(i, cost)\n",
        "    #plt.scatter(i, theta)  theta is a vector this doesnt make any sense\n",
        "    #if i == 100 :\n",
        "    print (cost)\n",
        "     \n",
        "  return theta1, theta2, b1, b2, Act2\n",
        "'''"
      ],
      "metadata": {
        "id": "Y6Ztin-YsRAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mXm9JxA6rxiX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}